{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# keras imports\n",
    "import keras\n",
    "from keras.applications import vgg16\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to get image names\n",
    "import os, cv2, random\n",
    "import ntpath\n",
    "\n",
    "# random seed to make the kernel reproducible\n",
    "random_seed = 123456789\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory where we are going to work on\n",
    "workdir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create result dir\n",
    "result_dir = './results' # define here the directory where your results will be saved\n",
    "if not os.path.exists(result_dir):\n",
    "    os.mkdir(result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**************************************************************************\n",
    "Content of **AVA.txt**\n",
    "**************************************************************************\n",
    "\n",
    "* **Column 1:** Index\n",
    "\n",
    "* **Column 2:** Image ID \n",
    "\n",
    "* **Columns 3 - 12:** Counts of aesthetics ratings on a scale of 1-10. Column 3 has counts of ratings of 1 and column 12 has counts of ratings of 10.\n",
    "\n",
    "* **Columns 13 - 14:** Semantic tag IDs. There are 66 IDs ranging from 1 to 66. The file tags.txt contains the textual tag corresponding to the numerical id. Each image has between 0 and 2 tags. Images with less than 2 tags have a \"0\" in place of the missing tag(s).\n",
    "\n",
    "* **Column 15:** Challenge ID. The file challenges.txt contains the name of the challenge corresponding to each ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the correct directory\n",
    "ava_dir = os.path.join(workdir, 'AVA.txt')\n",
    "ava_data_pd = pd.read_csv(ava_dir, sep = ' ', header = None, names = ['Index', 'Image ID', 'Rate 1', 'Rate 2',\n",
    "                                                                      'Rate 3', 'Rate 4', 'Rate 5', 'Rate 6', \n",
    "                                                                      'Rate 7', 'Rate 8', 'Rate 9','Rate 10', \n",
    "                                                                      'Sem 1', 'Sem 2', 'Challenge ID'])\n",
    "\n",
    "# separate the labels of the image IDs\n",
    "x_train = ava_data_pd.values[:,1]\n",
    "y_train = ava_data_pd.values[:,2:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample to see if everything has been loaded correctly\n",
    "ava_data_pd.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the data is loaded, we will check if all the images are in the directory and all that are not will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory of training images\n",
    "train_dir_images = os.path.join(workdir, 'images')\n",
    "\n",
    "# list containing the ids of the images that are not in the directory\n",
    "lost_images = []\n",
    "\n",
    "# iterate over all images\n",
    "for i in range(len(x_train)):\n",
    "    file_path = os.path.join(train_dir_images, str(x_train[i]) + '.jpg')\n",
    "    if not os.path.exists(file_path):\n",
    "        lost_images.append(i)\n",
    "\n",
    "# mask operations\n",
    "mask = np.ones((len(x_train),), bool)\n",
    "mask[lost_images] = False # set to false all lost images\n",
    "\n",
    "# prints number of lost images and original shape\n",
    "print(\"Total images lost: \", len(lost_images))\n",
    "print(\"Original dataset shape: \", x_train.shape)\n",
    "\n",
    "x_train = x_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "# resulting shape\n",
    "print(\"Resulting dataset shape: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metrics regarding score distribution\n",
    "mean_scores = np.sum(y_train * np.arange(1, 11), axis = 1) / (np.sum(y_train, axis = 1) + 1)\n",
    "mean_scores_rep = np.repeat(mean_scores, 10, axis = 0).reshape(len(y_train), 10)\n",
    "stds_scores = np.sqrt((np.sum(np.abs(np.arange(1, 11) - mean_scores_rep) ** 2 * y_train, axis = 1)) / (np.sum(y_train, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating distribution mean over all the dataset\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Histogram of mean scores')\n",
    "plt.hist(mean_scores, bins = 100)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Histogram of standard deviations')\n",
    "plt.hist(stds_scores, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# number of random samples to be plotted\n",
    "n_rand_samples = 3\n",
    "\n",
    "# define directory of training images\n",
    "train_dir_images = os.path.join(workdir, 'images')\n",
    "\n",
    "# plot n_rand_samples\n",
    "for i in range(n_rand_samples):\n",
    "\n",
    "    # pick random training image\n",
    "    case = os.path.join(train_dir_images, random.choice(os.listdir(train_dir_images)))\n",
    "    case_filename = os.path.splitext(ntpath.basename(case))[0] + '.jpg'\n",
    "    print(\"Filename: \", case_filename)\n",
    "    \n",
    "    # plot the score distribution of the image\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(2, 2, 2)\n",
    "\n",
    "    punt = y_train[x_train == int(os.path.splitext(ntpath.basename(case))[0])][0]\n",
    "    plt.title('Score distribution')\n",
    "    plt.bar(np.arange(1,11), height = punt, width = 0.9)\n",
    "\n",
    "    # open image with opencv and visualize it\n",
    "    plt.subplot(2, 2, 1)\n",
    "\n",
    "    image = cv2.cvtColor(cv2.imread(case, 1), cv2.COLOR_BGR2RGB) # cv2 loads an image BGR rather than RGB\n",
    "    plt.title('Image preview')\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the **255530** images are impossible to be loaded in memory, we will use a technique that will let us load images during the training process. Using this technique, we won't need to create a dataset beforehand and then use it to train you network, but we will just have a list of training images available, and images will be extracted **on-the-fly** during training. This strategy allows to save time in the preparation the static dataset as well as memmory, and allows the use of a dynamic generation of batches, where data augmentation can also be applied on-the-fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchCreator(object):\n",
    "\n",
    "    def __init__(self, x, y, batch_size, augmentation_fn=None):\n",
    "        '''\n",
    "        dataset: numpy array containing the Image IDs and the Rating distribution\n",
    "        '''\n",
    "        \n",
    "        # params\n",
    "        self.imgs_ids        = x                # image IDs\n",
    "        self.imgs_rates      = y                # image rate distribution\n",
    "        self.batch_size      = batch_size       # number of patches per batch\n",
    "        self.augmentation_fn = augmentation_fn  # augmentation function\n",
    "        \n",
    "        # batch information\n",
    "        self.n_samples = len(self.imgs_ids)\n",
    "        self.n_batches = self.n_samples // self.batch_size\n",
    "    \n",
    "        # information print\n",
    "        print('BatchCreator: {n_samples} patch samples.'.format(n_samples=self.n_samples))\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def __len__(self):\n",
    "        # length as number of batches\n",
    "        return self.n_batches\n",
    "\n",
    "    def next(self):\n",
    "        # build a mini-batch\n",
    "\n",
    "        batch_x = np.zeros((self.batch_size, 224, 224, 3), dtype = 'uint8')\n",
    "        batch_y = np.zeros((self.batch_size, 10)) # one-hot encoding\n",
    "\n",
    "        # load and return \"batch_size\" images\n",
    "        for i in range(self.batch_size):\n",
    "\n",
    "            # select case (generate random index)\n",
    "            img_index = np.random.choice(len(self.imgs_ids))\n",
    "\n",
    "            # obtain the path\n",
    "            case = os.path.join(train_dir_images, str(self.imgs_ids[img_index]) + '.jpg')\n",
    "\n",
    "            # load image, change color structure, resize it and store it\n",
    "            batch_x[i] = cv2.resize(cv2.cvtColor(cv2.imread(case, 1), cv2.COLOR_BGR2RGB), (224, 224))\n",
    "\n",
    "            # store score distribution\n",
    "            batch_y[i] = self.imgs_rates[img_index]/np.sum(self.imgs_rates[img_index])\n",
    "\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the BatchCreator is defined, it will be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_gen = BatchCreator(x_train, y_train, 16)\n",
    "\n",
    "# create a batch\n",
    "for batch_x, batch_y in training_gen:\n",
    "    print(batch_x.shape)\n",
    "    print(batch_y.shape)\n",
    "    break\n",
    "    \n",
    "# visualize it\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 18)\n",
    "f, axes = plt.subplots(4, 4)\n",
    "i = 0;\n",
    "for ax_row in axes:\n",
    "    for ax in ax_row:\n",
    "        ax.imshow(batch_x[i])\n",
    "        ax.axis('off')\n",
    "        ax.set_title('mean: {}'.format(np.sum(batch_y[i] * np.arange(0, 1)) / (np.sum(batch_y[i]) + 1)))\n",
    "        i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSequence(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, x, y, batch_size):\n",
    "\n",
    "        # params\n",
    "        self.imgs_ids   = x          # image IDs\n",
    "        self.imgs_rates = y          # image rate distribution\n",
    "        self.batch_size = batch_size # number of patches per batch\n",
    "        \n",
    "        # length\n",
    "        self.n_samples = len(self.imgs_ids)\n",
    "        self.n_batches = int(np.ceil(self.n_samples / self.batch_size))  # last mini-batch might be shorter\n",
    "        \n",
    "        # print some info\n",
    "        print('PatchSequence: {n_samples} patch samples.'.format(n_samples=self.n_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        # provide length in number of batches\n",
    "        return self.n_batches\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # create indexes for samples\n",
    "        idx1 = idx * self.batch_size\n",
    "        idx2 = np.min([idx1 + self.batch_size, self.n_samples])\n",
    "        idxs = np.arange(idx1, idx2)\n",
    "        \n",
    "        batch_x = np.zeros((len(idxs), 224, 224, 3), dtype = 'uint8')\n",
    "        batch_y = np.zeros((len(idxs), 10)) # one-hot encoding\n",
    "\n",
    "        # load and return \"batch_size\" images\n",
    "        for i in range(len(idxs)):\n",
    "\n",
    "            # obtain the path\n",
    "            case = os.path.join(train_dir_images, str(self.imgs_ids[idxs[i]]) + '.jpg')\n",
    "\n",
    "            # load image, change color structure, resize it and store it\n",
    "            batch_x[i] = cv2.resize(cv2.cvtColor(cv2.imread(case, 1), cv2.COLOR_BGR2RGB), (224, 224))\n",
    "\n",
    "            # store score distribution\n",
    "            batch_y[i] = self.imgs_rates[i]/np.sum(self.imgs_rates[idxs[i]])\n",
    "\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_gen = BatchSequence(x_train, y_train, 16)\n",
    "\n",
    "# create a batch\n",
    "for batch_x, batch_y in validation_gen:\n",
    "    print(batch_x.shape)\n",
    "    print(batch_y.shape)\n",
    "    break\n",
    "    \n",
    "# visualize it\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 18)\n",
    "f, axes = plt.subplots(4, 4)\n",
    "i = 0;\n",
    "for ax_row in axes:\n",
    "    for ax in ax_row:\n",
    "        ax.imshow(batch_x[i])\n",
    "        ax.axis('off')\n",
    "        ax.set_title('mean: {}'.format(np.sum(batch_y[i] * np.arange(1, 11)) / (np.sum(batch_y[i]) + 1)))\n",
    "        i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created the BatchCreator and the BatchSequence, we will split our dataset in trainig and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # a subset of samples will be extracted\n",
    "# perc = 1\n",
    "# num_samples = int(perc * len(y_train))\n",
    "# indxs = np.arange(len(y_train))\n",
    "# sel_idxs = np.random.choice(indxs, num_samples, replace = False)\n",
    "\n",
    "# # select the samples\n",
    "# x_train_sub = x_train[sel_idxs]\n",
    "# y_train_sub = y_train[sel_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split train and validationy_train\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, \n",
    "                                                                y_train, \n",
    "                                                                test_size = 0.2,\n",
    "                                                                random_state = random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the dataset, we will define the loss function `EMD` (Earth Moverâ€™s Distance). Whose equation is the following one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ EMD(p, \\widehat{p}) = \\left ( \\frac{1}{N} \\sum_{k=1}^{N} \\left | CDF_{p} \\left ( k \\right ) - CDF_{\\widehat{p}}\\left ( k \\right ) \\right |^{r} \\right )^{1/r} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where `CDF` is the cummulative distribution, and `r` is fixed to 2 to penalize the Euclidean distance between the\n",
    "CDFs and allows easier optimization when working with gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emd_loss(y_true, y_pred):\n",
    "    '''\n",
    "    Earth Mover's Distance loss\n",
    "    '''\n",
    "    cdf_p    = K.cumsum(y_true, axis = -1)\n",
    "    cdf_phat = K.cumsum(y_pred, axis = -1)\n",
    "    loss     = K.mean(K.sqrt(K.mean(K.square(K.abs(cdf_p - cdf_phat)), axis = -1)))\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the pre-trained model\n",
    "vgg_16 = vgg16.VGG16()\n",
    "\n",
    "vgg_16.summary()\n",
    "\n",
    "# remove last layer\n",
    "vgg_16.layers.pop()\n",
    "vgg_16.layers.pop()\n",
    "\n",
    "vgg_16.summary()\n",
    "\n",
    "# freeze all the layers\n",
    "for layer in vgg_16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# get the output of the model\n",
    "x = vgg_16.layers[-1].output\n",
    "    \n",
    "# add last FC layer\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "# create the new model\n",
    "vgg_16 = Model(vgg_16.input, x)\n",
    "\n",
    "# show summary\n",
    "vgg_16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learning rat\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# optimizer and model compile\n",
    "optimizer = Adam(lr = learning_rate)\n",
    "vgg_16.compile(optimizer, loss = emd_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "checkpoint = ModelCheckpoint(os.path.join(result_dir, 'best_model.h5'), \n",
    "                             monitor = 'val_loss',\n",
    "                             verbose = 1,\n",
    "                             save_weights_only = True,\n",
    "                             save_best_only = True,\n",
    "                             mode = 'min')\n",
    "\n",
    "# batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "\n",
    "# create the Batches and obtain the generatoros\n",
    "training_data = BatchCreator(x_train, y_train, batch_size)\n",
    "validation_data = BatchSequence(x_validation, y_validation, batch_size)\n",
    "\n",
    "# fit the model\n",
    "vgg_16.fit_generator(training_data,\n",
    "                     steps_per_epoch = 2000,\n",
    "                     epochs = epochs,\n",
    "                     verbose = 1, \n",
    "                     callbacks = [checkpoint],\n",
    "                     validation_data = validation_data,\n",
    "                     validation_steps = 300,\n",
    "                     workers = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of random samples to be plotted\n",
    "n_rand_samples = 3\n",
    "\n",
    "# obtain n_rand_samples from the validation subset\n",
    "val_indxs = np.random.randint(0, len(x_validation), n_rand_samples)\n",
    "val_images_name = x_validation[val_indxs] \n",
    "val_labels_true = y_validation[val_indxs]\n",
    "\n",
    "val_images = []\n",
    "\n",
    "# load the images into memmory\n",
    "for image in val_images_name:\n",
    "    case_filename = str(image) + '.jpg'\n",
    "    case = os.path.join(workdir, 'images', case_filename)\n",
    "    val_images.append(cv2.resize(cv2.cvtColor(cv2.imread(case, 1), cv2.COLOR_BGR2RGB), (224, 224)))\n",
    "\n",
    "val_images = np.array(val_images)\n",
    "val_labels_pred = vgg_16.predict(val_images)\n",
    "\n",
    "# plot n_rand_samples\n",
    "for i in range(n_rand_samples):\n",
    "\n",
    "    case_filename = str(val_images_name[i]) + '.jpg'\n",
    "    case = os.path.join(workdir, 'images', case_filename)\n",
    "    print(\"Filename: \", case_filename)\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    # open image with opencv and visualize it\n",
    "    plt.subplot(2, 3, 1)\n",
    "    image = cv2.cvtColor(cv2.imread(case, 1), cv2.COLOR_BGR2RGB) # cv2 loads an image BGR rather than RGB\n",
    "    plt.title('Image preview')\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    # plot the ground truth score distribution of the image\n",
    "    plt.subplot(2, 3, 2)\n",
    "    punt_true = val_labels_true[i]\n",
    "    plt.title('Ground truth score distribution')\n",
    "    plt.bar(np.arange(1,11), height = punt_true, width = 0.9)\n",
    "    \n",
    "    # plot the predicted score distribution of the image\n",
    "    plt.subplot(2, 3, 3)\n",
    "    punt_pred = val_labels_pred[i]\n",
    "    plt.title('Predicted score distribution')\n",
    "    plt.bar(np.arange(1,11), height = punt_pred, width = 0.9)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
